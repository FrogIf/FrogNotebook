<!DOCTYPE html>
<html>
<head>
<title>kafka.md</title>
<meta http-equiv="Content-type" content="text/html;charset=UTF-8">

<style>
/* https://github.com/microsoft/vscode/blob/master/extensions/markdown-language-features/media/markdown.css */
/*---------------------------------------------------------------------------------------------
 *  Copyright (c) Microsoft Corporation. All rights reserved.
 *  Licensed under the MIT License. See License.txt in the project root for license information.
 *--------------------------------------------------------------------------------------------*/

body {
	font-family: var(--vscode-markdown-font-family, -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif);
	font-size: var(--vscode-markdown-font-size, 14px);
	padding: 0 26px;
	line-height: var(--vscode-markdown-line-height, 22px);
	word-wrap: break-word;
}

#code-csp-warning {
	position: fixed;
	top: 0;
	right: 0;
	color: white;
	margin: 16px;
	text-align: center;
	font-size: 12px;
	font-family: sans-serif;
	background-color:#444444;
	cursor: pointer;
	padding: 6px;
	box-shadow: 1px 1px 1px rgba(0,0,0,.25);
}

#code-csp-warning:hover {
	text-decoration: none;
	background-color:#007acc;
	box-shadow: 2px 2px 2px rgba(0,0,0,.25);
}

body.scrollBeyondLastLine {
	margin-bottom: calc(100vh - 22px);
}

body.showEditorSelection .code-line {
	position: relative;
}

body.showEditorSelection .code-active-line:before,
body.showEditorSelection .code-line:hover:before {
	content: "";
	display: block;
	position: absolute;
	top: 0;
	left: -12px;
	height: 100%;
}

body.showEditorSelection li.code-active-line:before,
body.showEditorSelection li.code-line:hover:before {
	left: -30px;
}

.vscode-light.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(0, 0, 0, 0.15);
}

.vscode-light.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(0, 0, 0, 0.40);
}

.vscode-light.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-dark.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 255, 255, 0.4);
}

.vscode-dark.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 255, 255, 0.60);
}

.vscode-dark.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

.vscode-high-contrast.showEditorSelection .code-active-line:before {
	border-left: 3px solid rgba(255, 160, 0, 0.7);
}

.vscode-high-contrast.showEditorSelection .code-line:hover:before {
	border-left: 3px solid rgba(255, 160, 0, 1);
}

.vscode-high-contrast.showEditorSelection .code-line .code-line:hover:before {
	border-left: none;
}

img {
	max-width: 100%;
	max-height: 100%;
}

a {
	text-decoration: none;
}

a:hover {
	text-decoration: underline;
}

a:focus,
input:focus,
select:focus,
textarea:focus {
	outline: 1px solid -webkit-focus-ring-color;
	outline-offset: -1px;
}

hr {
	border: 0;
	height: 2px;
	border-bottom: 2px solid;
}

h1 {
	padding-bottom: 0.3em;
	line-height: 1.2;
	border-bottom-width: 1px;
	border-bottom-style: solid;
}

h1, h2, h3 {
	font-weight: normal;
}

table {
	border-collapse: collapse;
}

table > thead > tr > th {
	text-align: left;
	border-bottom: 1px solid;
}

table > thead > tr > th,
table > thead > tr > td,
table > tbody > tr > th,
table > tbody > tr > td {
	padding: 5px 10px;
}

table > tbody > tr + tr > td {
	border-top: 1px solid;
}

blockquote {
	margin: 0 7px 0 5px;
	padding: 0 16px 0 10px;
	border-left-width: 5px;
	border-left-style: solid;
}

code {
	font-family: Menlo, Monaco, Consolas, "Droid Sans Mono", "Courier New", monospace, "Droid Sans Fallback";
	font-size: 1em;
	line-height: 1.357em;
}

body.wordWrap pre {
	white-space: pre-wrap;
}

pre:not(.hljs),
pre.hljs code > div {
	padding: 16px;
	border-radius: 3px;
	overflow: auto;
}

pre code {
	color: var(--vscode-editor-foreground);
	tab-size: 4;
}

/** Theming */

.vscode-light pre {
	background-color: rgba(220, 220, 220, 0.4);
}

.vscode-dark pre {
	background-color: rgba(10, 10, 10, 0.4);
}

.vscode-high-contrast pre {
	background-color: rgb(0, 0, 0);
}

.vscode-high-contrast h1 {
	border-color: rgb(0, 0, 0);
}

.vscode-light table > thead > tr > th {
	border-color: rgba(0, 0, 0, 0.69);
}

.vscode-dark table > thead > tr > th {
	border-color: rgba(255, 255, 255, 0.69);
}

.vscode-light h1,
.vscode-light hr,
.vscode-light table > tbody > tr + tr > td {
	border-color: rgba(0, 0, 0, 0.18);
}

.vscode-dark h1,
.vscode-dark hr,
.vscode-dark table > tbody > tr + tr > td {
	border-color: rgba(255, 255, 255, 0.18);
}

</style>

<style>
/* Tomorrow Theme */
/* http://jmblog.github.com/color-themes-for-google-code-highlightjs */
/* Original theme - https://github.com/chriskempson/tomorrow-theme */

/* Tomorrow Comment */
.hljs-comment,
.hljs-quote {
	color: #8e908c;
}

/* Tomorrow Red */
.hljs-variable,
.hljs-template-variable,
.hljs-tag,
.hljs-name,
.hljs-selector-id,
.hljs-selector-class,
.hljs-regexp,
.hljs-deletion {
	color: #c82829;
}

/* Tomorrow Orange */
.hljs-number,
.hljs-built_in,
.hljs-builtin-name,
.hljs-literal,
.hljs-type,
.hljs-params,
.hljs-meta,
.hljs-link {
	color: #f5871f;
}

/* Tomorrow Yellow */
.hljs-attribute {
	color: #eab700;
}

/* Tomorrow Green */
.hljs-string,
.hljs-symbol,
.hljs-bullet,
.hljs-addition {
	color: #718c00;
}

/* Tomorrow Blue */
.hljs-title,
.hljs-section {
	color: #4271ae;
}

/* Tomorrow Purple */
.hljs-keyword,
.hljs-selector-tag {
	color: #8959a8;
}

.hljs {
	display: block;
	overflow-x: auto;
	color: #4d4d4c;
	padding: 0.5em;
}

.hljs-emphasis {
	font-style: italic;
}

.hljs-strong {
	font-weight: bold;
}
</style>

<style>
/*
 * Markdown PDF CSS
 */

 body {
	font-family: -apple-system, BlinkMacSystemFont, "Segoe WPC", "Segoe UI", "Ubuntu", "Droid Sans", sans-serif, "Meiryo";
	padding: 0 12px;
}

pre {
	background-color: #f8f8f8;
	border: 1px solid #cccccc;
	border-radius: 3px;
	overflow-x: auto;
	white-space: pre-wrap;
	overflow-wrap: break-word;
}

pre:not(.hljs) {
	padding: 23px;
	line-height: 19px;
}

blockquote {
	background: rgba(127, 127, 127, 0.1);
	border-color: rgba(0, 122, 204, 0.5);
}

.emoji {
	height: 1.4em;
}

code {
	font-size: 14px;
	line-height: 19px;
}

/* for inline code */
:not(pre):not(.hljs) > code {
	color: #C9AE75; /* Change the old color so it seems less like an error */
	font-size: inherit;
}

/* Page Break : use <div class="page"/> to insert page break
-------------------------------------------------------- */
.page {
	page-break-after: always;
}

</style>

<script src="https://unpkg.com/mermaid/dist/mermaid.min.js"></script>
</head>
<body>
  <script>
    mermaid.initialize({
      startOnLoad: true,
      theme: document.body.classList.contains('vscode-dark') || document.body.classList.contains('vscode-high-contrast')
          ? 'dark'
          : 'default'
    });
  </script>
<h1 id="kafka">Kafka</h1>
<h2 id="%E6%A6%82%E8%BF%B0">概述</h2>
<p>Kafka是一款开源的消息引擎. 消息引擎系统是一组规范, 企业利用这组规范在不同系统之间传递语义准确的消息, 实现松耦合的异步式数据传递. 同时, kafka也是一个分布式流处理平台.</p>
<p>消息引擎的作用: 1. 削峰填谷; 2. 发送方与接收方松耦合.</p>
<p>消息传输有两种模型:</p>
<ol>
<li>点对点模型;</li>
<li>发布/订阅模型;</li>
</ol>
<h2 id="%E5%9F%BA%E6%9C%AC%E6%A6%82%E5%BF%B5">基本概念</h2>
<ul>
<li>Topic
<ul>
<li>发布订阅的对象</li>
</ul>
</li>
<li>Producer
<ul>
<li>向topic发送消息的客户端应用程序称为Producer</li>
<li>一个Producer可以向多个topic发送消息</li>
</ul>
</li>
<li>Consumer
<ul>
<li>订阅topic中消息的客户端应用程序称为Consumer</li>
<li>一个Consumer可以订阅多个topic上的消息</li>
</ul>
</li>
<li>Broker
<ul>
<li>kafka服务进程, 即kafka集群中的节点</li>
</ul>
</li>
<li>Partition
<ul>
<li>将一个topic下的所有消息进行分区, 每个分区存储一部分消息(类似于es中的分片)</li>
<li>Partition使得kafka具备了水平扩展能力</li>
</ul>
</li>
<li>Replica
<ul>
<li>在kafka集群中, 为保证高可用, 对于每一个Partition, 都会有多个副本</li>
<li>Leader Replica: 对外提供服务, 生产者总向leader replica写消息, 消费者总从leader replica读取消息</li>
<li>Follower Replica: 不会对外提供服务, 向leader replica发送请求, 保持与leader replica的同步</li>
</ul>
</li>
<li>Offset
<ul>
<li>消息位移 - 每条消息在Partition中的位置信息(注意, 同一topic的不同Partition中offset可以是相同的)</li>
</ul>
</li>
<li>Consumer Offset
<ul>
<li>消费者位移 - 表征消费者消费进度, 每个consumer都有自己的消费者位移</li>
</ul>
</li>
<li>Consumer Group
<ul>
<li>多个消费者共同组成一个消费者组, 同时消费一个topic的多个分区, 以实现高吞吐.</li>
</ul>
</li>
<li>Rebalance
<ul>
<li>重平衡, 消费者组中有实例宕机后, 其他消费者自动重新分配订阅的topic的分区的过程</li>
<li>rebalance是kafka消费者端实现高可用的重要手段</li>
<li>rebalance过程中, 所有consumer都会停止消费</li>
</ul>
</li>
<li>record
<ul>
<li>消息, kafka中消息是以byte数组的方式 进行传输的</li>
</ul>
</li>
<li>Coordinator
<ul>
<li>协调者, Consumer只与Coordinator所在的broker进行交互, 包括位移提交等. 然后由Coordinator负责消费者组的注册, 成员管理等元数据操作; 每个Broker启动时, 都会创建一个Coordinator, 然后通过算法, 确定为某个ConsumerGroup服务的Coordinator.</li>
</ul>
</li>
</ul>
<blockquote>
<p>Leader Replica和Follower Replica其实就是master和slave, 只不过美国那边master和slave是敏感词, 所以就改成leader和follower了</p>
</blockquote>
<p>kafka的三层消息架构: topic --&gt; partition --&gt; 消息</p>
<p>Kafka持久化:</p>
<ul>
<li>Kafka使用日志来保存数据, 只存在追加写</li>
<li>kafka底层将日志又分为多个日志段, 后台定期删除比较老的日志段</li>
</ul>
<p>Zookeeper</p>
<p>在xxx版本之前的kafka需要使用zookeeper做分布式协调. zookeeper中会保存kafka集群的所有元信息, 例如broker列表, topic信息等.</p>
<h2 id="kafka-broker%E5%8F%82%E6%95%B0%E9%85%8D%E7%BD%AE">Kafka Broker参数配置</h2>
<h4 id="broker%E7%BA%A7%E5%88%AB%E5%8F%82%E6%95%B0">Broker级别参数</h4>
<ul>
<li><code>log.dirs</code>: broker需要使用的文件路径, 多个路径使用逗号分隔</li>
<li><code>zookeeper.connect</code>: 指定kafka集群的zookeeper信息</li>
<li><code>listeners</code>: 配置对外开放的端口号协议类型, 同时会附带上当前主机的主机名</li>
<li><code>advertised.listeners</code>: 与<code>listeners</code>基本一致, 用于外网访问</li>
<li><code>auto.create.topics.enable</code>: 是否允许自动创建topic</li>
<li><code>unclean.leader.election.enable</code>: 是否允许unclean leader选举, 如果只剩下数据滞后比较多的副本, 是否允许这些副本成为leader</li>
<li><code>auto.leader.rebalance.enable</code>: 是否允许定期进行leader选举</li>
<li><code>log.retention.{hour|minutes|ms}</code>: 控制一条消息数据被保存多长时间, 默认7天</li>
<li><code>log.retention.bytes</code>: 是指定Broker为消息保存的总磁盘容量大小, 默认-1, 即不受限制</li>
<li><code>message.max.bytes</code>: 控制Broker能够接收的最大消息大小</li>
</ul>
<h4 id="topic%E7%BA%A7%E5%88%AB%E5%8F%82%E6%95%B0">Topic级别参数</h4>
<p>topic级别参数如果与broker级别有冲突, 优先使用topic级别.</p>
<ul>
<li><code>retention.ms</code>: topic下消息的保存时间</li>
<li><code>retention.bytes</code>: 指定一个topic下的日志所占用的最大磁盘容量</li>
</ul>
<blockquote>
<p>关于topic参数, 可以在创建topic/修改topic时, 通过命令指定的.</p>
</blockquote>
<h4 id="jvm%E5%8F%82%E6%95%B0">JVM参数</h4>
<ul>
<li><code>KAFKA_HEAP_OPTS</code>: 指定java堆大小</li>
<li><code>KAFKA_JVM_PERFORMANCE_OPTS</code>: 指定GC参数</li>
</ul>
<blockquote>
<p>这两个都配置到环境变量中即可</p>
</blockquote>
<h2 id="%E7%94%9F%E4%BA%A7%E8%80%85">生产者</h2>
<p>生产者可以自定分区策略:</p>
<ol>
<li>轮询策略: 默认分区策略;</li>
<li>随机策略</li>
<li>按消息键保序策略: 通过这个策略, 可以保证具有相同特征的消息分配到同一个分区上, 从而保证了消息消费顺序</li>
</ol>
<h2 id="consumer-group">Consumer Group</h2>
<p>Consumer Group是Kafka提供的可扩展且具有容错性的消费者机制. kafka通过consumer group可以同时实现点对点模型和发布/订阅模型.</p>
<ul>
<li>Consumer Group之间彼此独立，互不影响，它们能够订阅相同的一组主题而互不干涉</li>
<li>如果所有消费者实例同属于一个group, 则它实现的是点对点模式</li>
<li>如果消费者实例属于不同的group, 则它实现的是发布/订阅模式</li>
<li>一个Partition只能由一个消费组中的一个Consumer消费</li>
</ul>
<h2 id="%E6%B6%88%E6%81%AF">消息</h2>
<h4 id="%E4%BF%9D%E8%AF%81%E6%B6%88%E6%81%AF%E4%B8%8D%E4%B8%A2%E5%A4%B1">保证消息不丢失</h4>
<p>Kafka对已提交的消息做有限度的持久化保证.</p>
<ul>
<li>已提交的消息: kafka的Broker接收到一条消息, 并写入到日志文件后, 会告诉生产者这条消息已成功提交;</li>
<li>有限度的持久化: 至少有一个Broker存活.</li>
</ul>
<p>丢失场景:</p>
<ul>
<li>生产者程序丢失
<ul>
<li>异步发送消息, 发送后不管, 导致实际上消息没有发送成功, 也没有返回日志</li>
<li>解决方案: 使用带有回调通知的发送API, producer.send(msg, callback)</li>
</ul>
</li>
<li>消费者程序丢失数据
<ul>
<li>根本原因: 实际消费位移与提交的消费位移不一致</li>
<li>场景一:
<ul>
<li>先提交位移, 然后消费了其中一部分后终止了, 导致再次消费时, 从已提交的位移开始消费, 丢失了一部分消息</li>
<li>解决方案: 先消费, 再提交位移</li>
</ul>
</li>
<li>场景二:
<ul>
<li>自动提交位移, 导致一部分消息消费失败之后, 无法重新消费</li>
<li>解决方案: 不使用自动提交位移, 保证消费成功之后再提交位移</li>
</ul>
</li>
</ul>
</li>
</ul>
<p>最佳实践:</p>
<ul>
<li>Producer端
<ul>
<li>使用producer.send(msg, callback)</li>
<li>设置acks=all, 表明所有副本Broker都要接收到消息, 才算已提交</li>
<li>设置自动重试retries为一个较大值</li>
</ul>
</li>
<li>Broker端
<ul>
<li>unclean.leader.election.enable = false, 使得非ISR副本不参与leader选举</li>
<li>replication.factor &gt;= 3, 副本数</li>
<li>min.insync.replicas &gt; 1, 控制消息至少被写入多少个副本才算已提交</li>
<li>replication.factor &gt; min.insync.replicas, 如果两者相等, 只要有一个副本挂了, 整个分区就无法正常工作了</li>
</ul>
</li>
<li>Customer端
<ul>
<li>enable.auto.commit = false, 禁用自动提交, 采用手动提交位移</li>
</ul>
</li>
</ul>
<h4 id="%E6%B6%88%E6%81%AF%E4%BA%A4%E4%BB%98%E5%8F%AF%E9%9D%A0%E6%80%A7%E4%BF%9D%E9%9A%9C">消息交付可靠性保障</h4>
<p>消息投递语义:</p>
<ul>
<li>最多一次(at most once): 消息可能会丢失, 但绝对不会被重复发送;</li>
<li>至少一次(at least once): 消息不会丢失, 但是可能被重复发送;</li>
<li>精确一次(exactly once): 消息不会丢失, 也不会被重复发送.</li>
</ul>
<p>kafka默认提供的可靠性语义是--至少一次. 每条消息提交成功之后, broker会返回提交成功的响应. 如果由于某种原因, Producer没有收到这个响应, 就会导致消息重复提交.</p>
<p>如何通过kafka做到精确一次?</p>
<ul>
<li>幂等型Producer
<ul>
<li>props.put(&quot;enable.idempotence&quot;, true)或者props.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true), broker端自动会进行幂等校验</li>
<li>只能保证单分区幂等</li>
<li>只能保证单会话幂等(一旦重启, 幂等性保证就丧失了)</li>
</ul>
</li>
<li>事务型Producer
<ul>
<li>保证了多分区的事务原子性的写入, 保证一批消息要么全部成功, 要么全部失败</li>
<li>配置与幂等型相同: enable.idempotence=true</li>
<li>设置Producer端参数transactional.id为一个有意义的名字</li>
<li>默认read_uncommitted级别, Consumer能够读取到 Kafka 写入的任何消息，不论事务型 Producer 提交事务还是终止事务，其写入的消息都可以读取.</li>
<li>read_committed级别, 保证多条消息原子性的写入目标分区, 保证Consumer只能看到事务成功提交的消息</li>
</ul>
</li>
</ul>
<p>事务型Producer示例:</p>
<pre class="hljs"><code><div>producer.initTransactions();
<span class="hljs-keyword">try</span>{
    producer.beginTransaction();
    producer.send(record1);
    producer.send(record2);
    producer.commitTransaction();
}<span class="hljs-keyword">catch</span>(KafkaException e){
    producer.abortTransaction();
}
</div></code></pre>
<h2 id="%E4%BD%8D%E7%A7%BB">位移</h2>
<h4 id="%E4%BD%8D%E7%A7%BB%E4%B8%BB%E9%A2%98">位移主题</h4>
<ul>
<li>__consumer_offsets被称作位移主题</li>
<li>用处
<ul>
<li>保存kafka消费者的位移信息;</li>
<li>保存ConsumerGroup信息;</li>
<li>保存用于删除Group过期位移甚至删除Group的消息. 此时消息体为空</li>
</ul>
</li>
<li>配置
<ul>
<li>offsets.topic.num.partitions - 位移主题的分区数, 默认50</li>
<li>offsets.topic.replication.factor - 位移主题的副本数, 默认是3</li>
</ul>
</li>
<li>过期消息的删除
<ul>
<li>kafka后台有专门的线程(LogCleaner), 定期巡检位移主题, 如果发现同一个key存在多条消息, 只保留最后一条, 删除其余消息</li>
</ul>
</li>
</ul>
<h4 id="%E4%BD%8D%E7%A7%BB%E7%9A%84%E6%8F%90%E4%BA%A4">位移的提交</h4>
<p>这里的位移指的是消费者位移, 是consumer要消费的下一条消息的位移.</p>
<p>每个partition有自己独立的位移, 所以, 位移提交也是在分区粒度上进行的.</p>
<ul>
<li>自动提交
<ul>
<li>enable.auto.commit = true</li>
<li>auto.commit.interval.ms - 自动提交位移的时间间隔</li>
</ul>
</li>
<li>手动提交
<ul>
<li>enable.auto.commit = false</li>
<li>consumer.commitSync() - 调用</li>
</ul>
</li>
</ul>
<blockquote>
<p>自动提交存在的问题: 如果是多个线程异步消费, 自动提交有可能造成消息丢失; 如果是同步消费, 自动提交是在poll调用时, 触发提交上一次的offset, 有时会导致重复消费</p>
</blockquote>
<p>自动提交的相关配置:</p>
<pre class="hljs"><code><div>Properties props = <span class="hljs-keyword">new</span> Properties();
props.put(<span class="hljs-string">"bootstrap.servers"</span>, <span class="hljs-string">"localhost:9092"</span>);
props.put(<span class="hljs-string">"group.id"</span>, <span class="hljs-string">"test"</span>);
props.put(<span class="hljs-string">"enable.auto.commit"</span>, <span class="hljs-string">"true"</span>);
props.put(<span class="hljs-string">"auto.commit.interval.ms"</span>, <span class="hljs-string">"2000"</span>);
props.put(<span class="hljs-string">"key.deserializer"</span>, <span class="hljs-string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);
props.put(<span class="hljs-string">"value.deserializer"</span>, <span class="hljs-string">"org.apache.kafka.common.serialization.StringDeserializer"</span>);
KafkaConsumer&lt;String, String&gt; consumer = <span class="hljs-keyword">new</span> KafkaConsumer&lt;&gt;(props);
consumer.subscribe(Arrays.asList(<span class="hljs-string">"foo"</span>, <span class="hljs-string">"bar"</span>));
<span class="hljs-keyword">while</span> (<span class="hljs-keyword">true</span>) {
    ConsumerRecords&lt;String, String&gt; records = consumer.poll(<span class="hljs-number">100</span>);
    <span class="hljs-keyword">for</span> (ConsumerRecord&lt;String, String&gt; record : records)
        System.out.printf(<span class="hljs-string">"offset = %d, key = %s, value = %s%n"</span>, record.offset(), record.key(), record.value());
}
</div></code></pre>
<p>手动同步提交位移的代码:</p>
<pre class="hljs"><code><div><span class="hljs-keyword">while</span> (<span class="hljs-keyword">true</span>) {
    ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofSeconds(<span class="hljs-number">1</span>));
    process(records); <span class="hljs-comment">// 处理消息</span>
    <span class="hljs-keyword">try</span> {
        consumer.commitSync();
    } <span class="hljs-keyword">catch</span> (CommitFailedException e) {
        handle(e); <span class="hljs-comment">// 处理提交失败异常</span>
    }
}
</div></code></pre>
<p>手动提交的最佳实践(伪代码):</p>
<pre class="hljs"><code><div><span class="hljs-keyword">try</span> {
           <span class="hljs-keyword">while</span>(<span class="hljs-keyword">true</span>) {
                        ConsumerRecords&lt;String, String&gt; records = 
                                    consumer.poll(Duration.ofSeconds(<span class="hljs-number">1</span>));
                        process(records); <span class="hljs-comment">// 处理消息</span>
                        commitAysnc(); <span class="hljs-comment">// 使用异步提交规避阻塞</span>
            }
} <span class="hljs-keyword">catch</span>(Exception e) {
            handle(e); <span class="hljs-comment">// 处理异常</span>
} <span class="hljs-keyword">finally</span> {
            <span class="hljs-keyword">try</span> {
                        consumer.commitSync(); <span class="hljs-comment">// 最后一次提交使用同步阻塞式提交</span>
  } <span class="hljs-keyword">finally</span> {
       consumer.close();
}
}
</div></code></pre>
<h4 id="%E5%A4%84%E7%90%86%E4%BD%8D%E7%A7%BB%E6%8F%90%E4%BA%A4%E5%A4%B1%E8%B4%A5">处理位移提交失败</h4>
<p>当客户端位移提交失败时, 会返回:<code>CommitFailedException</code>异常.</p>
<p>位移提交失败的常见情况是: 消费者消费消息的时间太长, 超过了<code>max.poll.interval.ms</code>, 触发了rebalance, 导致kafka集群已经将该consumer视为下线. 解决办法是:</p>
<ol>
<li>调高<code>max.poll.interval.ms</code>值;</li>
<li>减少<code>max.poll.records</code>, 使得每次从kafka批量获取的消息记录数小一些, 从而能尽快处理完成;</li>
<li>通过多线程异步消费, 提高消费速度.</li>
</ol>
<h2 id="%E9%81%BF%E5%85%8D%E6%84%8F%E5%A4%96%E7%9A%84rebalance">避免意外的rebalance</h2>
<p>那种情况属于意外的rebalance? 应用活跃中, 但是被错误的视为下线, 触发整体rebalance.</p>
<ul>
<li>一个应用如何向kafka证明自己还活着?
<ul>
<li>每个consumer会定期向coordinate发送心跳, 证明自己在线</li>
<li>心跳的响应中, 如果包含<code>REBALANCE_NEEDED</code>, consumer就会开始rebalance</li>
<li>consumer端参数<code>session.timeout.ms</code>表征一个consumer发送心跳的超时时间, 默认10s, 超过这个时间没有发送心跳, 就会被视为下线</li>
<li>consumer端参数<code>heartbeat.interval.ms</code>指示consumer发送心跳的时间间隔</li>
<li>consumer端参数<code>max.poll.interval.ms</code>限定了consumer调用poll方法的时间间隔, 默认5分钟, 也就是说如果一个程序5分钟内没有消费完一条消息, consumer会自动发起离组</li>
</ul>
</li>
</ul>
<p>具体来说, 意外的触发rebalance有以下几种原因:</p>
<ol>
<li>未能及时发送心跳数据;</li>
<li>consumer消费时间过长, 触发离组.</li>
</ol>
<blockquote>
<p>有时, 客户端fullgc过于频繁, fullgc时间过长, 也会导致消费时间过长, 进而导致rebalance</p>
</blockquote>
<blockquote>
<p>Coordinator所在的broker日志，如果经常发生rebalance，会有类似于&quot;(Re)join group&quot; 之类的日志</p>
</blockquote>
<h2 id="%E5%85%B6%E4%BB%96">其他</h2>
<h4 id="%E6%8B%A6%E6%88%AA%E5%99%A8">拦截器</h4>
<ul>
<li>Producer端拦截器 - org.apache.kafka.clients.producer.ProducerInterceptor
<ul>
<li>onSend: 该方法会在消息发送之前被调用, 可以对消息进行加工</li>
<li>onAcknowledgement: 该方法会在消息成功提交或发送失败之后, callback方法执行前调用. 需要注意线程安全问题, 并且不要加入过重的逻辑.</li>
</ul>
</li>
<li>Consumer端拦截器 - org.apache.kafka.clients.consumer.ConsumerInterceptor
<ul>
<li>onConsume: 消息被consumer处理之前被调用</li>
<li>onCommit: Consumer 在提交位移之后调用该方法</li>
</ul>
</li>
<li>使用场景: 监控, 审计等</li>
</ul>
<p>使用示例:</p>
<pre class="hljs"><code><div>Properties props = new Properties();
List&lt;String&gt; interceptors = new ArrayList&lt;&gt;();
interceptors.add(&quot;com.yourcompany.kafkaproject.interceptors.AddTimestampInterceptor&quot;); // 拦截器1
interceptors.add(&quot;com.yourcompany.kafkaproject.interceptors.UpdateCounterInterceptor&quot;); // 拦截器2
props.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, interceptors);
……
</div></code></pre>
<h4 id="%E6%B6%88%E8%B4%B9%E8%BF%9B%E5%BA%A6%E7%9B%91%E6%8E%A7">消费进度监控</h4>
<ul>
<li>lag: 滞后程度, 指消费者当前落后于生产者的速度. lag的单位是消息数, 在kafka中是针对每一个分区的指标.
<ul>
<li>这个值变大, 说明消费端的消费能力不够, 赶不上生产端的生产能力了</li>
</ul>
</li>
<li>lead: 消费者最新消费的位移与分区当前第一条消息的位移的差值.
<ul>
<li>由于消息留存时间, 这个值变小, 说明删除速度快追上生产速度了, 有可能会导致一部分没有消费的消息直接被删除, 造成消息丢失</li>
</ul>
</li>
</ul>
<blockquote>
<p>JMX指标中的records-lag-avg和records-lead-avg指标</p>
</blockquote>
<h4 id="%E5%89%AF%E6%9C%AC">副本</h4>
<p>In-sync Replicas, ISR, 同步副本. 如果一个副本, 滞后的时间小于<code>replica.lag.time.max.ms</code>, 则被视为ISR.</p>
<p>一般副本的作用有: 1. 提供数据冗余; 2. 提供高伸缩性; 3. 改善数据局部性.</p>
<p>kafka只能提供 数据冗余, 对于后两者, 不能支持.</p>
<h4 id="%E6%8E%A7%E5%88%B6%E5%99%A8">控制器</h4>
<p>控制器组件是kafka的核心组件, 作用是在zookeeper的帮助下, 协同管理整个kafka集群. 集群中任意一个broker都可以当做控制器, 集群中只能存在一个控制器.</p>
<blockquote>
<p>控制器, 和ElasticSearch中的master节点功能类似. 但是人家es的master都不需要依赖zookeeper, 哎!</p>
</blockquote>
<p>第一个在zookeeper中创建<code>/controller</code>节点的broker会成为控制器节点. 控制器的具体作用如下:</p>
<ol>
<li>主题管理（创建、删除、增加分区）</li>
<li>分区重分配</li>
<li>Preferred 领导者选举</li>
<li>集群成员管理（新增 Broker、Broker 主动关闭、Broker 宕机）</li>
<li>数据服务</li>
</ol>
<p>控制器中保存了所有主题的信息, 所有broker的信息, 分区信息等.</p>
<h4 id="%E9%AB%98%E6%B0%B4%E4%BD%8D">高水位</h4>
<p>kafka中的高水位是用来表征消息的位移的, 高水位以下的消息是已提交的消息, 高水位以高水位以上的消息是未提交的消息. 主要有两个作用:</p>
<ol>
<li>定义消息可见性，即用来标识分区下的哪些消息是可以被消费者消费的</li>
<li>帮助Kafka完成副本同步</li>
</ol>
<h2 id="%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4">常用命令</h2>
<ul>
<li>消费数据</li>
</ul>
<pre class="hljs"><code><div>bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test-topic --from-beginning --consumer.config aaa.properties
</div></code></pre>
<ul>
<li>查看消费组的消费情况</li>
</ul>
<pre class="hljs"><code><div>bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --group test-group --describe --command-config aaa.properties
</div></code></pre>
<ul>
<li>查看消费组列表</li>
</ul>
<pre class="hljs"><code><div>bin/kafka-consumer-groups.sh --bootstrap-server localhost:9092 --list --command-config aaa.properties
</div></code></pre>
<ul>
<li>查看topic明细</li>
</ul>
<pre class="hljs"><code><div>bin/kafka-topics.sh --describe --bootstrap-server node1:9092,node2:9092,node3:9092 --topic topicName --command-config aaa.properties
</div></code></pre>
<p>查询结果示例如下:</p>
<pre class="hljs"><code><div>  Topic:topicName PartitionCount:3 ReplicationFactor:2 Configs:
      Topic: topicName Partition: 0 Leader: 0 Replicas: 0,1 Isr: 0,1
      Topic: topicName Partition: 1 Leader: 1 Replicas: 1,2 Isr: 1,2
      Topic: topicName Partition: 2 Leader: 2 Replicas: 2,0 Isr: 2,0
</div></code></pre>
<p>PartitionCount：partition 个数。
ReplicationFactor：副本个数。
Partition：partition 编号，从 0 开始递增。
Leader：当前 partition 起作用的 breaker.id。
Replicas: 当前副本数据所在的 breaker.id，是一个列表，排在最前面的其作用。
Isr：当前 kakfa 集群中可用的 breaker.id 列表。</p>
<ul>
<li>一般上面的配置文件中这样配置:</li>
</ul>
<pre class="hljs"><code><div><span class="hljs-meta">bootstrap.servers</span>=<span class="hljs-string">localhost:9093</span>
<span class="hljs-meta">group.id</span>=<span class="hljs-string">test-consumer-group</span>
<span class="hljs-meta">security.protocol</span>=<span class="hljs-string">SASL_PLAINTEXT</span>
<span class="hljs-meta">sasl.mechanism</span>=<span class="hljs-string">PLAIN</span>
</div></code></pre>

</body>
</html>
